{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 4. For a given text file exclude the stop words and\n",
    "perform the Stemming & lemmatization and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "word=[]\n",
    "data=open('NLPdataEx3&4-data_in.txt')\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "for  i in data.readlines():\n",
    "    word +=word_tokenize(i)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " '?',\n",
       " 'Weather',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'Its',\n",
       " 'raining',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'Mr.',\n",
       " 'Raja',\n",
       " ',',\n",
       " '?',\n",
       " 'Weather',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'Its',\n",
       " 'raining',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'Mr.',\n",
       " 'Raja',\n",
       " ',',\n",
       " '.',\n",
       " 'Weather',\n",
       " 'bad',\n",
       " '.',\n",
       " 'Its',\n",
       " 'heavily',\n",
       " 'raining',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'great',\n",
       " 'technique',\n",
       " '.',\n",
       " 'It',\n",
       " 'nice',\n",
       " 'learn',\n",
       " 'technique',\n",
       " '.',\n",
       " 'AI',\n",
       " 'making',\n",
       " 'difference',\n",
       " 'world',\n",
       " '.',\n",
       " 'It',\n",
       " 'would',\n",
       " 'helpful',\n",
       " 'betterment',\n",
       " 'human',\n",
       " 'life',\n",
       " '.',\n",
       " 'We',\n",
       " 'need',\n",
       " 'make',\n",
       " 'advantage',\n",
       " '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words \n",
    "filtered_word=[w for w in word if not w in stop_words]\n",
    "\n",
    "filtered_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##setmming\n",
    "ps=PorterStemmer()\n",
    "lem=WordNetLemmatizer()\n",
    "\n",
    "stem=[ps.stem(sw) for sw in filtered_word]\n",
    "lemt=[lem.lemmatize(ls) for ls in filtered_word]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " ',',\n",
       " '?',\n",
       " 'weather',\n",
       " 'awesom',\n",
       " '.',\n",
       " 'it',\n",
       " 'rain',\n",
       " '.',\n",
       " 'hello',\n",
       " 'mr.',\n",
       " 'raja',\n",
       " ',',\n",
       " '?',\n",
       " 'weather',\n",
       " 'awesom',\n",
       " '.',\n",
       " 'it',\n",
       " 'rain',\n",
       " '.',\n",
       " 'hello',\n",
       " 'mr.',\n",
       " 'raja',\n",
       " ',',\n",
       " '.',\n",
       " 'weather',\n",
       " 'bad',\n",
       " '.',\n",
       " 'it',\n",
       " 'heavili',\n",
       " 'rain',\n",
       " '.',\n",
       " 'nlp',\n",
       " 'great',\n",
       " 'techniqu',\n",
       " '.',\n",
       " 'It',\n",
       " 'nice',\n",
       " 'learn',\n",
       " 'techniqu',\n",
       " '.',\n",
       " 'AI',\n",
       " 'make',\n",
       " 'differ',\n",
       " 'world',\n",
       " '.',\n",
       " 'It',\n",
       " 'would',\n",
       " 'help',\n",
       " 'better',\n",
       " 'human',\n",
       " 'life',\n",
       " '.',\n",
       " 'We',\n",
       " 'need',\n",
       " 'make',\n",
       " 'advantag',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemed items\n",
    "stem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " '?',\n",
       " 'Weather',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'Its',\n",
       " 'raining',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'Mr.',\n",
       " 'Raja',\n",
       " ',',\n",
       " '?',\n",
       " 'Weather',\n",
       " 'awesome',\n",
       " '.',\n",
       " 'Its',\n",
       " 'raining',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'Mr.',\n",
       " 'Raja',\n",
       " ',',\n",
       " '.',\n",
       " 'Weather',\n",
       " 'bad',\n",
       " '.',\n",
       " 'Its',\n",
       " 'heavily',\n",
       " 'raining',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'great',\n",
       " 'technique',\n",
       " '.',\n",
       " 'It',\n",
       " 'nice',\n",
       " 'learn',\n",
       " 'technique',\n",
       " '.',\n",
       " 'AI',\n",
       " 'making',\n",
       " 'difference',\n",
       " 'world',\n",
       " '.',\n",
       " 'It',\n",
       " 'would',\n",
       " 'helpful',\n",
       " 'betterment',\n",
       " 'human',\n",
       " 'life',\n",
       " '.',\n",
       " 'We',\n",
       " 'need',\n",
       " 'make',\n",
       " 'advantage',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatized words\n",
    "lemt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##common words in both the stem and lemt\n",
    "commonwords=list(set(stem).intersection(set(lemt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'human',\n",
       " 'learn',\n",
       " 'make',\n",
       " 'bad',\n",
       " ',',\n",
       " '.',\n",
       " 'life',\n",
       " 'world',\n",
       " 'nice',\n",
       " 'AI',\n",
       " 'need',\n",
       " 'would',\n",
       " 'We',\n",
       " 'It',\n",
       " '?']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
